# 第二章、用好大模型



## 1、借助API让大模型自动化地处理任务



学完本课程后，你将能够：

- 了解如何借助大模型服务的 API 来自动地处理一批任务
- 思考和发现你的业务可以借助大模型提效的机会











## 2、通过优化提示词来提升回答质量



学完本课程后，你将能够：

- 了解什么是提示词工程**（Prompt Engineering）**
- 获得更高质量的提示词的技巧





**提示词工程（Prompt Engineering）**就是研究如何构建和调整提示词，从而让大语言模型实现各种符合用户预期的任务的过程。就像跟AI沟通的艺术，为了让像Qwen这样的大语言模型更好地理解你的需求，你需要清晰地描述你的需求，提供必要的背景信息，明确告诉AI你想让它做什么。就像跟人沟通一样，你需要不断调整你的表达方式，直到AI理解你的意思，并给出你想要的答案。



### 2.1 直接提问

直接提问，也称为**零样本提示（Zero-Shot Prompting），**即不给大语言模型提供案例，完全依靠 LLM 理解和处理能力完成任务。前文给的提示词例子，都属于直接提问。目前大部分开源和商用的大语言模型已经经过了大量的预训练和指令调试，能够很好的理解并响应用户的直接提问。适用于**目标明确、问题简单、答案确定且唯一**等场景。

直接提问时，可遵循以下原则：

- **简洁**：尽量用最简短的方式表达问题。过于冗长的问题可能包含多余的信息，导致模型理解错误或答非所问。
- **具体**：避免抽象的问题，确保问题是具体的，不含糊。
- **详细上下文**：如果问题涉及特定上下文或背景信息，要提供足够的详情以帮助模型理解，即使是直接提问也不例外。
- **避免歧义**：如果一个词或短语可能有多重含义，要么明确其含义，要么重新表述以消除歧义。
- **逻辑清晰**：问题应逻辑连贯，避免出现逻辑上的混淆或矛盾，这样才能促使模型提供有意义的回答。



```
提示词：
这批红色的苹果水果外观怎么样，新鲜吗？

输出：
新鲜。
```



### 2.2 增加示例

在提示词中提供少量（通常几个或几十个）示例，也称为**少样本提示（Few-Shot Prompting）**，以帮助模型更好地理解任务要求和期望输出。比如：

- 让 LLM 跟随我们所要求的规范、格式、概念、文法、语气进行输出。
- 提供进一步推理的参考，比如让大模型学会数学运算或按照示例方式进行逻辑推理。



```
提示词：
要求：请根据以下电影评论，判断其情感评价（正面、负面或中性）。
示例1：这部电影剧情引人入胜，但特效炸裂。情感评价：正面
示例2：虽然这部电影剧情单调，但特效却非常炸裂。情感评价：负面+正面
示例3：这部电影不好不坏。情感评价：中性
待分类评论：这部电影音乐动人，但剧情略显平淡。


输出：
情感评价：正面+负面
解释：评论中提到“音乐动人”属于正面评价，表明了对电影音乐部分的喜爱和赞赏。然而，紧接着的“但剧情略显平淡”则为负面评价，表达了对电影剧情的不满或失望。因此，整体评价是正面和负面情感的混合。
```



值得一提的是，这种方式比较适合翻译量不大，且示例的数量可穷举的场景，可以轻量、快速地完成翻译工作。但是当需要成千上万的专业术语词条示例辅助翻译的场景，这种方式就不够了，也不够方便，我们可以让大语言模型接入专业的术语库，来增强大语言模型的能力，也即**检索增强生成（Retrieval-Augmented Generation），简称RAG**，我们在后续课程会展开讲解。



### 2.3 分配角色

赋予模型一个具体的角色或身份，如“作为经验丰富的营养师”，来引导模型在特定角色视角下生成回答。

分配角色适用以下场景：

- 需要专业知识或特定视角的问题解答。例如，模拟老师、医生、律师等回答相关领域的问题。
- 模拟特定人物或角色的语言风格。例如，模仿某个著名人物（如历史人物或文学角色）语言风格的文本时。
- 进行角色扮演游戏或创作。在创意写作或角色扮演游戏中扮演指定的角色，与使用者进行互动。
- 在特定行业内进行决策模拟。例如，模拟一个管理咨询师来分析商业案例或提供商业建议。



```
提示词：
你是一名酒店评论家，请对刚入住的酒店进行评价。

提示词：
你是一名刚上小学的学生，请对训练营入住的酒店进行评价。
```





### 2.4 限定输出风格/格式

大语言模型非常善于撰写论文、文章等内容，不过如果我们仅仅简单地告诉大语言模型一些宽泛的提示，比如：



```
提示词：写一篇关于桥的短篇小说，要求叙事风格诙谐幽默
```



### 2.5 拆解复杂任务

把一个复杂的任务，拆解成多个稍微简单的任务，让大语言模型**分步**来思考问题，称为**思维链（Chain-of-Thought Prompting, CoT）**提示，这种方式可让大语言模型像人类一样逐步解释或进行推理，从而极大地提升 LLM 的能力。与前面介绍的标准提示不同，该方法不仅寻求答案，还**要求模型解释其得出答案的步骤**。

下图展示了标准提示与思维链提示的对比。



```
提示词：
小明有20个苹果，吃了两个，又买了5个，小明现在一共有多少苹果，通过思维链CoT的方式来分析。

输出：
初始小明最初有20个苹果。小明吃了2个苹果后，他剩下20−2=18个苹果。接着，小明又买了5个苹果，所以他现在的苹果数量是 18+5=23个苹果。
因此，通过这个思维链的分析，我们可以得出结论：小明现在一共有23个苹果。
```

上面思维链提示中没有给 LLM 提供问题解析示例，所以也可以称为**零样本思维链（Zero-shot CoT）**，相对应地在增加了示例后就变成了**少样本思维链（Few-shot Cot）。**

```
少样本思维链 Few-shot CoT
提示词：
问题：小宝有三盒糖果，每盒糖果有10颗糖，小宝一共有多少颗糖果？
答案：小宝有三盒糖果，每盒糖果有10颗，那么他一共有的糖果数量就是： 3盒 × 10颗/盒 = 30颗，小宝一共有30颗糖果。
问题：小明有20个苹果，吃了2个苹果，又买了5个苹果，小明一共有多少颗苹果？
答案：给出逐步思考过程
```



### 2.6 提示词框架

**实际上提示词可以包含以下任意要素：**

**指令 Instruction**：需要模型去做什么，如回答某个问题、撰写某种类型的文章或按照特定格式进行总结。指令应该简洁、明确，确保 LLM 能够理解任务的目标和要求。

**背景信息 Context**：背景信息可以包括任务的背景、目的相关的各类信息，还可以为 LLM 设置角色背景、观点立场等信息，LLM 将在此背景下进行回应或生成文本。

**参考样本 Examples**：与解决用户问题相关的示例，比如通过少样本提示的方式帮助 LLM 更好理解如何处理指令。

**输入数据 Input Data**：用户输入指令和要求，比如用什么语气，生成多少字的内容。

**输出指示 Output Indicator**：指定输出的类型或格式，我们可以给出限定关键词、限制条件或要求的输出格式/方式（如表格），也可以避免无关或不期望的信息出现。



结合上述要素，我们可以根据任务的复杂度来设计提示词，具体有以下几种情况：

1. **纯指令型**：最直接的互动方式，仅通过简明指令向模型提出需求，适合于寻求快速、基本答案的场景。
2. **背景**+**指令**：在指令基础上融入背景信息，为模型创造一个理解和响应任务的框架，尤其适用于需要考虑特定情境或角色定位的任务。
3. **指令**/**背景**+**输出指示**：在基础指令或背景信息之上，加入输出指示，精确指导模型如何组织和呈现答案，以满足特定的格式或风格要求。
4. **综合型提示**：结合指令、背景信息、输入数据与输出指示，形成一个全方位的引导体系。这种复合型提示尤为强大，能够在复杂任务中提高模型输出的针对性与质量，尤其是在模型需要从示例中学习并模仿特定风格或结构时。



```
提示词：
背景知识：“阿里云弹性容器实例 ECI（Elastic Container Instance）是敏捷安全的Serverless容器运行服务。您无需管理底层服务器，也无需关心运行过程中的容量规划，只需要提供打包好的Docker镜像，即可运行容器，并仅为容器实际运行消耗的资源付费。”
请参考如上背景知识回答如下问题：
问题：阿里云弹性容器实例 ECI 是用来运行什么的？
回答：分别使用中文和英文回答
```

我们来拆解下这个示例：

**背景信息**：【背景知识：“阿里云...资源付费”】

**指令**：【请参考如上背景知识回答如下问题】

**输入数据**：【问题：阿里云弹性容器实例 ECI 是用来运行什么的？】

**输出指示**：【回答：分别使用中文和英文回答】





### 2.7 推理模型

**什么是推理模型？**

推理模型通常指专门优化用于逻辑推理、问题解决、多步推断等任务的模型（如DeepSeek-R1、o1），它们通常在数学解题、代码生成、逻辑分析等方面有更好的表现。

与通用模型相比，推理模型拥有更强的逻辑能力，因为它经过了大量的专项训练，能够更好地理解复杂的问题，并且在解答时更有条理。但并不是说就一定比通用模型更好，两种模型都有各自的应用场景，下表从一些典型维度对这两类模型进行了对比：





**如何有效地提示推理模型？**

推理模型在面对相对模糊的任务也能给出详尽且格式良好的响应。因此，使用本节前面提到的一些提示词技巧（如指示模型“逐步思考”）可能反而限制了模型的推理。下面列举了一些适用于推理模型的提示技巧：

- **直接提问**：保持提示**简洁、清晰**，且明确任务限制。
- **避免思维链提示**：你无需提示推理模型“逐步思考”或“解释你的推理”，它们本身会进行深入的思考。
- **根据模型响应调整提示词**：直接提问推理模型通常能够产生良好的响应，但如果你有更复杂精细的要求，可以在提示词中明确，比如有**明确的输入信息和输出要求**时，你可以通过**增加示例**明确这些信息，还可以通过**分隔符**帮助推理模型区分不同的信息模块。这个过程可以是重复多次的，不断尝试调整提示，让模型不断推理迭代，直到符合你的要求。







## 3、通过插件增强大模型的能力

大模型插件是一种软件组件，它们设计用于增强和扩展基础大模型的功能。如网络搜索、视觉生成、语音合成等。





典型的插件包括：

- 基础工具，如**计算器**、时钟、天气信息、股票行情
- 可以让用户获得实时性消息的插件，比如体育赛事报道、实时、热点新闻
- 可以为模型拓展更多能力的插件，比如图片生成、语音合成、代码解释器







- 如果你正准备基于百炼上提供的通义千问 API 服务构建大模型应用，可以查看[百炼插件概述](https://help.aliyun.com/document_detail/2743342.html)来了解百炼平台预置的插件能力（包括图片生成、夸克搜索、Python代码解释器、计算器等），以及了解如何增加自定义的插件。
- 阿里云的模型服务灵积产品中提供了[兼容 OpenAI API 的通义千问 API](https://help.aliyun.com/zh/dashscope/developer-reference/compatibility-of-openai-with-dashscope)，该 API 也支持 OpenAI 的 function call 能力。如果你的业务是面向中文用户居多，或者需要满足国内大模型应用备案的要求，可以借助该兼容 API，在不修改业务代码的情况下将你的大模型应用背后的 OpenAI API 替换为通义千问 API。









## 4、通过微调改善大模型在垂直领域的表现

**RAG**类似于考生应对开卷考试的过程，考试前不需要对书本内容进行过多的学习和理解，在作答的过程中通过翻阅相关内容找到最相关的部分，提取信息然后结合问题完成回答。

**微调**则类似于考生应对闭卷考试的过程，考生需要在考试前经过老师的教学，把书本上的内容吃透，才能写出正确答案。



核心思想：在预训练的基础上，使用特定领域的数据对模型进行进一步的训练，从而让模型更擅长处理你想要解决的问题，也就是说，**让大模型更懂你**。



### 4.1 微调的流程

（1）数据准备



（2）模型选择。

本示例中使用的是Qwen-7B-chat。



（3）模型微调

```
!deepspeed /ml/code/train_sft.py \
--model_name_or_path qwen-7b-chat/ \
--train_path train.json \
--valid_path valid.json \
--learning_rate 1e-5 \
--lora_dim 32 \
--max_seq_len 256 \
--model qwen \
--num_train_epochs 20 \
--per_device_train_batch_size 32 \
--zero_stage 2 \
--gradient_checkpointing \
--print_loss \
--deepspeed \
--output_dir output/ \
--offload
```



（4）模型测评

查看微调后模型的表现



（5）模型集成



（6）测试和优化



（7）模型部署



（8）监控与维护



（9）持续迭代



### 4.2 微调的方式

从调整参数量的大小这个角度，我们可以把微调分为**全参微调**与**高效微调**（Parameter-Efficient Fine-Tuning）。

当前比较主流的 PEFT 方法包括 Adapter Tuning、Prefix Tuning、Prompt Tuning、LoRA 等等。













## 5、通过RAG增强大模型回答原本无法回答的问题



检索增强生成（RAG，Retrieval Augmented Generation）



你报名参与了导游志愿者活动，但对景点并不熟悉的你很难给出令游客满意的景点介绍。你意识到可以通过查询资料来帮助你完成导游工作，这时的你不再扮演知识的输出者，而是知识的总结者。同样地，给大模型配备知识库，也可以让它参考查询到的信息回答原本无法回答的问题。这种结合了信息检索与文本生成的方法就是我们本节课程要介绍的检索增强生成（RAG，Retrieval Augmented Generation）方法。





学完本课程后，你将能够：

- 了解什么是RAG，以及它的实现原理
- 动手给大模型增加知识库来实现RAG
- 了解如何持续改进RAG应用效果



### 5.1 什么是RAG

增加私域定制化知识库，来增加大模型回答的准确度。

**检索增强生成**包括三个步骤，建立**索引**、**检索**、**生成**





### 5.2 RAG原理



![img](https://scms-prod-sh-public.oss-cn-shanghai.aliyuncs.com/course_picture/alqvxlczbkggibwjnoji.png)









### 5.3 如何持续改进RAG的应用效果

随着深入使用，你可能发现你的 RAG 应用可能只是能用了，但还有很多问题，比如：

- **问题比较抽象或者概念比较模糊**
- 知识库没有检索到问题的答案
- 缺少对答案做兜底验证的机制



**评测标准**

在评测指标设计上，我们主要考察**检索**模块的准确性，如准确率、召回率、F1值等等；在**生成**模块，我们主要考察生成答案的价值，如相关性、真实性等等。







### 改造一：提升索引准确率

- **优化文本解析过程**

在构建知识库的时候，我们首先需要正确的从文档中提取有效语料。

- **优化chunk切分模式**

当你在处理大量的文本、数据或知识时，如果你一次性全部交给大模型来阅读和处理，效率是非常低的。所以，我们把它们切分成更小、更易管理的部分，这些部分就是chunk。

- **自动合并检索**

这个策略是将文档分块，建成一棵语料块的树，比如1024切分、512切分、128切分，并构造出一棵文档结构树。

- **选择更适合业务的Embedding模型**

经过切分的语料块在提供检索服务之前，我们需要把chunk语料块由原来的文本内容转换为机器可以用于比对计算的一组数字，即变为Embedding向量。我们通过Embedding模型来进行这个转换。

- **选择更适合业务的ReRank模型**

除了优化生成向量的质量，我们还需要同时优化做向量排序的ReRank模型，好的ReRank模型会让更贴近用户问题的chunks的排名更靠前。

- **Raptor 用聚类为文档块建立索引**

还有一类有意思的做法是采用无监督聚类来生成文档索引。这就像通过文档的内容为文档自动建立目录的过程。







### 改造二：让问题更好理解

针对这个问题进行尝试的论文很多，提供了很多有意思的实现思路，如Multi-Query、RAG-Fusion、Decomposition、Step-back、HyDE等等，我们简要讲解一下这些方法的思路。

- **Enrich 完善用户问题**

我们通过多轮对话逐步确认用户需求。

- **Multi-Query 多路召回**

多路召回的方法不是让大模型进行一次改写然后反复向用户确认，而是让大模型自己解决如何理解用户的问题。所以我们首先一次性改写出多种用户问题，让大模型根据用户提出的问题，从多种不同角度去生成有一定提问角度或提问内容上存在差异的问题。让这些存在差异的问题作为大模型对用户真实需求的猜测，然后再把每个问题分别生成答案，并总结出最终答案。

- **RAG-Fusion 过滤融合**

在经过多路召回获取了各种语料块之后，并不是将所有检索到的语料块都交给大模型，而是先进行一轮筛选，给检索到的语料块进行去重操作，然后按照与原问题的相关性进行排序，再将语料块打包喂给大模型来生成答案。

- **Step Back 问题摘要**

让大模型先对问题进行一轮抽象，从大体上去把握用户的问题，获得一层高级思考下的语料块。

- **Decomposition 问题分解**

这个策略讲究细节，有点像提示词工程中的CoT（Chain of Thoughts，思维链）的概念，是把用户的问题拆成一个一个小问题来理解，或者可以说是RAG中的CoT。

- **HyDE 假设答案**

这个策略让大模型先来根据用户的问题生成一段假设答案，然后用这段假设的答案作为新的问题去文档库里匹配新的文档块，再进行总结，生成最终答案。





### 改造三：改造信息抽取途径

**Corrective Retrieval Augmented Generation (CRAG)**是一种改善提取信息质量的策略：如果通过知识库检索得到的信息与用户问题相关性太低，我们就主动搜索互联网，将网络搜索到的信息与知识库搜索到的信息合并，再让大模型进行整理给出最终答案。

在工程上我们可以有两种实现方式：

1. **向量相似度**，我们用检索信息得到的向量相似度分来判断。判断每个语料块与用户问题的相似度评分，是否高过某个阈值，如果搜索到的语料块与用户问题的相似度都比较低，就代表知识库中的信息与用户问题不太相关；
2. **直接问大模型**，我们可以先将知识库检索到的信息交给大模型，让大模型自主判断，这些资料是否能回答用户的问题。



在CRAG的论文中，当面临知识库不完备的情况时，先从互联网下载相关资料再回答的准确率比直接回答的准确率有了较大提升。





### 改造四：回答前反复思考

Self-RAG，也称为self-reflection，是一种通过在应用中设计**反馈路径**实现**自我反思**的策略。基于这个思想，我们可以让应用问自己三个问题：

- **相关性**：我获取的这些材料和问题相关吗？
- **无幻觉**：我的答案是不是按照材料写的来讲，还是我自己编造的？
- **已解答**：我的答案是不是解答了问题？





### 改造五：从多种数据源中获取资料

- **从数据库中获取统计指标**

大模型可以将用户问题转化为SQL语句去数据库中检索相关信息，这个能力就是NL2SQL（Natural Language to SQL）。

- **从知识图谱中获取数据**

Neo4j是一款图数据库引擎，可以为我们提供知识图谱构建和计算服务。





### 总结

![img](https://scms-prod-sh-public.oss-cn-shanghai.aliyuncs.com/course_picture/moiqpihulxuvpigtbbot.png)











## 6、借助Agent让大模型应用思考、决策并执行任务

你也许尝试过让大模型基于你的工作总结写一份周报，然后你再手动发送周报的邮件给你老板。如果有一个程序可以接收这样的输入，把你的工作总结转化为周报，还能通过电子邮件发送给你的老板，这样的程序就是本章节即将介绍的“Agent”。接下来，我们将带你拆解Agent背后的实现思路，并探索单Agent、多Agent在现实世界的应用。



学完本课程后，你将能够：

- 了解大模型 Agent 是什么，能解决什么问题
- 了解人机交互的前沿方向，激发创新性思考





### 6.1 大模型Agent是什么

**从软件工程的角度来看，大模型Agent是指基于大语言模型的，能使用工具与外部世界进行交互的计算机程序。**

如果把Agent类比成人类，那么大模型相当于大脑，而工具就是四肢。Agent能够通过工具实现与外部世界的交互，而工具通常就是之前介绍过的插件。





### （1） 让Agent具备记忆能力

短期记忆（Short-Term Memory）

想象你在超级市场购物时，暂时记住了一串购物清单，但一旦结账离开后，这些信息会很快就忘记了。这就是短期记忆，它帮助我们处理和暂时存储当前需要的信息。

长期记忆（Long-Term Memory）

长期记忆是指我们大脑中长期存储的信息，比如你的童年回忆、学习到的知识和技能。这些信息可以存储非常久，有时甚至是一辈子。

在大模型Agent中，长期记忆对应着系统持久化的信息，如业务历史记录、知识库等，通常存储在外部向量数据库和文档库中，Agent会利用长期记忆来回答用户私有知识或专业领域相关的问题。





### （2） 让Agent具备规划能力

**任务分解**

（1）思维链（Chain of Thought，CoT）

把复杂任务分解为链式思维最早是用来解决数学题的。如下图所示，我们想让大模型来求解 (23-20+6=?) 这样的数学题，但是早期的大模型往往搞不清多步数学运算的内在逻辑，算不准。后来，[Wei等人（2022）](https://arxiv.org/abs/2201.11903)发现了这个CoT的方法，如果我们在提示词里明确写上让大模型“**一步一步思考**”，那么大模型就会开始拆解计算的步骤，最后得到正确的结果。



（2）**思维树ToT（Tree of Thought）**

思维树（ToT）则进一步扩展了思维链的概念，通过构建一个具有分支和选择的树形结构来处理复杂问题。





### **小结**

了解了大模型Agent的能力之后，我们简单总结一下Agent相对于大模型有什么区别。

1. 它不局限于输出回答，还能通过插件（工具）**与外部世界交互**，例如发送邮件、发布文章、联网查询、执行代码、下单购物等……理论上只要是计算机程序能做的事情，它都能做到。
2. 它不再是被动式地接受多轮提问，而是能**自主地推理**（拆解任务、选择最优路径）、**主动纠错、自主完成任务**。你可以让它每完成一个或多个步骤就给你同步进展，和你确认下一步的动作，也可以授权它自主地完成所有步骤。
3. 它不仅可以完成简单的事情，还能**完成复杂的任务**，比如搭建一个网站、开发一款游戏，因为它能拆解任务、自我纠错、调用外部工具等。
4. 它可以自我迭代，**吸取历史经验**，不断成长，因为它不仅能记住这次会话里你对它的指导，还能记住以前的会话里你给它提过的要求。
5. 它不仅能完成通用的任务，还能**完成特定领域的任务**，因为它可以接入特定领域的外部知识库和工具。







### 6.2 Agent 应用场景



ModelScope-Agent

利用ModelScope-Agent框架开发的Agent，除了可以提供文本创作之外，还能生成图片、视频、语音等内容。单个Agent具有角色扮演、LLM调用、工具使用、规划、记忆等能力。

你可以直接访问[魔搭空间](https://modelscope.cn/studios)来体验ModelScope-Agent，如果你感兴趣，也可以下载代码在本地运行 ./examples 中的案例。

项目地址：https://github.com/modelscope/modelscope-agent/





### 6.3 Multi-Agent









## 7、大模型应用的安全合规



### 7.1 大模型的风险

个人信息泄露

内容安全风险：包括但不限于违法或不良信息、虚假内容、偏见和歧视等

模型安全风险：DDOS攻击

知识产权风险：爬虫获取图片







大模型应用备案

自2023年8月15日起，《生成式人工智能服务管理暂行办法》正式生效，监管部门要求对AIGC（生成式人工智能）相关的APP和小程序进行整改和合规备案：

- 已上架但未完成合规手续的应用将被下架。
- 未上架的应用必须完成合规动作后方可上线。

**解决方案**：阿里云百炼大模型服务平台为云上企业提供技术支持，涉及合规要求的算法备案。详情参见[通义大模型应用上架及合规备案](https://help.aliyun.com/document_detail/2667824.html?spm=a2c4g.2400264.0.i1)。











































